---
layout: post
title: My Blog Post 6
---

In this blog post, I’ll write a tutorial on a **fake news classifier** using `Tensorflow`.

Similar to my last post, everything below is ran on Google Colab since it can boost up the speed of modeling.


```python
# The followings are the Packages/Modules required in this post.
import pandas as pd
import nltk
from nltk.corpus import stopwords
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import losses
import re
import string
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.layers.experimental.preprocessing import StringLookup
import numpy as np
# for embedding viz
from sklearn.decomposition import PCA
import plotly.express as px 
import plotly.io as pio
pio.templates.default = "plotly_white"
# for plot
from matplotlib import pyplot as plt
import plotly.express as px 
from plotly.io import write_html
```

# §1. Acquire Training Data

Let's take a look at a dataset accessed [from Kaggle](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset).


```python
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
# read the data
data = pd.read_csv(train_url)
```






Note: the dataset above should be cleaned already, and can be performed a train-test split. As can be seen, each row of the data corresponds to an article. The `title` column gives the title of the article, while the `text` column gives the full article text. The `fake`, is either `0` or `1` depended on if the article is `true` or `fake` respectively.

# §2. Make a Dataset

Next, I will first split the dataset into training and testing, and then write a function called `make_dataset`, which can:

- Replace **stopwords** like “the,” “and,” or “but.” with an empty space, "". Please read [this](https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe).

- Before returning, I will batch it into small chunks of data using a command likes `my_data_set.batch(100)`. This helps with training runtime later although it may cause loss of accuracy.

- return a `tf.data.Dataset` with two "inputs", `(title, text)`, and one "output", where consists only of the fake column. Please read [this](https://nbviewer.org/github/PhilChodrow/PIC16B/blob/master/lectures/tf/tf-4.ipynb)

Here's the code:


```python
# get stopwords from nltk.corpus
nltk.download('stopwords')
stop = stopwords.words('english')
```

    [nltk_data] Downloading package stopwords to /root/nltk_data...
    [nltk_data]   Package stopwords is already up-to-date!
    


```python
def make_dataset(df):
  # remove the stopwords in text
  df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
  # remove the stopwords in title
  df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
  # create a tf.data.Dataset
  df_new = tf.data.Dataset.from_tensor_slices(
    (
        # input
        {
            "title": df[["title"]],
            "text": df[["text"]]
        },
        # output
        {
            "fake": df[["fake"]]
        }
    )
  )
  df_new = df_new.batch(100)
  return df_new
```


```python
# get the new dataframe
df = make_dataset(data)
# get the training and validation
df = df.shuffle(buffer_size = len(df))
train_size = int(0.8*len(df))
val_size   = int(0.2*len(df))

train = df.take(train_size)
val   = df.skip(train_size).take(val_size)
# check
len(train), len(val)
```




    (180, 45)




```python
# compute a base rate such that a model might always say “fake news!”
freq = data.groupby("fake").size()
base = freq[1] / (freq[0] + freq[1])
base
```




    0.522963160942581



Our base rate is 52%!

# §3. Create Models

Please use TensorFlow models to offer a perspective on the following question:
Considering the following question:

`When detecting fake news, is it most effective to focus on only the title of the article, the full text of the article, or both?`

My guess for this question is *both*. But let's use three `TensorFlow` models to address it:

- model1: use only the article title as an input.

- model2: use only the article text as an input.

- model3: use both the article title and the article text as input.

For each model, I will train them on the training data seperately until they appear to be “fully” trained. Then, for the comparison in model performance, I will use a visualization of the training histories to get a clear look.

Note: 

- For the first two models, instead of creating new datasets, it will be simpler to just specify the inputs to the `keras.Model` appropriately because `TensorFlow` will automatically ignore the unused inputs in the dataset.

- From last post, we've learned to use **Sequential** API for case that have only one input for spliting out a single output. But in this example, having two distinct kinds of inputs, text and title, we need to construct a new model using a somewhat more manual approach, **Functional** API. When using the Functional API, it is possible to use the same layer in multiple parts of the model. Please read [this](https://www.tensorflow.org/guide/keras/functional). In addition, one suggestion is to share an `embedding layer` for both the article title and text inputs.

- When encounter overfitting, using `Dropout` layers may be helpful.

Before modeling, we first start with writing a function named `standardization()` to standarize the data, which converts all characters into lower case and replace the punctuations with an empty space, "". Then, we continue to write a model named `TextVectorization` that will count the frequency of words and help display them by their ranking.


```python
# only the top 2000 distinct words will be tracked
size_vocabulary = 2000

def standardization(input_data):
    lowercase = tf.strings.lower(input_data)
    no_punctuation = tf.strings.regex_replace(lowercase,
                                  '[%s]' % re.escape(string.punctuation),'')
    return no_punctuation 

vectorize_layer = TextVectorization(
    standardize=standardization,
    max_tokens=size_vocabulary, # only consider this many words
    output_mode='int',
    output_sequence_length=500) 

vectorize_layer.adapt(train.map(lambda x, y: x["title"]))
```

When working on the inputs part, we need to be aware that both the `title` and the `text` column contain just one entry for each article. So, the shape should be `(1,)` (a tuple of length 1).


```python
# inputs

title_input = keras.Input(
    shape = (1,), 
    name = "title",
    dtype = "string"
)

text_input = keras.Input(
    shape = (1,), 
    name = "text",
    dtype = "string"
)
```

Let's try to create a 10-dimensional embedding when constructing our model for both title and text inputs. Keep it in mind that state-of-the-art embeddings will typically have a much higher number of dimensions.


```python
shared_embedding = layers.Embedding(size_vocabulary, 10, name = "embedding")
```

## Model1 with title only:


```python
title_features = vectorize_layer(title_input)
title_features = shared_embedding(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.GlobalAveragePooling1D()(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.Dense(32, activation='relu')(title_features)

# with one more output layers for the number of class
output1 = layers.Dense(2, name = "fake")(title_features)

# here's our model1:

model1 = keras.Model(
    inputs = title_input,
    outputs = output1
)

model1.summary()
```

    Model: "model"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     title (InputLayer)          [(None, 1)]               0         
                                                                     
     text_vectorization (TextVec  (None, 500)              0         
     torization)                                                     
                                                                     
     embedding (Embedding)       (None, 500, 10)           20000     
                                                                     
     dropout (Dropout)           (None, 500, 10)           0         
                                                                     
     global_average_pooling1d (G  (None, 10)               0         
     lobalAveragePooling1D)                                          
                                                                     
     dropout_1 (Dropout)         (None, 10)                0         
                                                                     
     dense (Dense)               (None, 32)                352       
                                                                     
     fake (Dense)                (None, 2)                 66        
                                                                     
    =================================================================
    Total params: 20,418
    Trainable params: 20,418
    Non-trainable params: 0
    _________________________________________________________________
    


```python
# Something a bit more visually attractive can be obtained by using the plot_model function:
keras.utils.plot_model(model1)
```




    
![output_19_0.png]({{ site.baseurl }}/images/output_19_0.png)
    




```python
model1.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)

history1 = model1.fit(train, 
                    validation_data=val,
                    epochs = 30, 
                    verbose = True)
```

    Epoch 1/30
    

    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning:
    
    Input dict contained keys ['text'] which did not match any model input. They will be ignored by the model.
    
    

    180/180 [==============================] - 5s 24ms/step - loss: 0.6906 - accuracy: 0.5250 - val_loss: 0.6872 - val_accuracy: 0.5237
    Epoch 2/30
    180/180 [==============================] - 4s 20ms/step - loss: 0.6549 - accuracy: 0.6850 - val_loss: 0.5860 - val_accuracy: 0.9281
    Epoch 3/30
    180/180 [==============================] - 4s 19ms/step - loss: 0.4477 - accuracy: 0.9190 - val_loss: 0.3044 - val_accuracy: 0.9484
    Epoch 4/30
    180/180 [==============================] - 3s 19ms/step - loss: 0.2395 - accuracy: 0.9492 - val_loss: 0.1757 - val_accuracy: 0.9611
    Epoch 5/30
    180/180 [==============================] - 4s 21ms/step - loss: 0.1589 - accuracy: 0.9589 - val_loss: 0.1287 - val_accuracy: 0.9640
    Epoch 6/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.1218 - accuracy: 0.9666 - val_loss: 0.0922 - val_accuracy: 0.9767
    Epoch 7/30
    180/180 [==============================] - 3s 19ms/step - loss: 0.0980 - accuracy: 0.9730 - val_loss: 0.0842 - val_accuracy: 0.9771
    Epoch 8/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0856 - accuracy: 0.9748 - val_loss: 0.0735 - val_accuracy: 0.9751
    Epoch 9/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0756 - accuracy: 0.9776 - val_loss: 0.0640 - val_accuracy: 0.9831
    Epoch 10/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0684 - accuracy: 0.9788 - val_loss: 0.0593 - val_accuracy: 0.9822
    Epoch 11/30
    180/180 [==============================] - 3s 17ms/step - loss: 0.0630 - accuracy: 0.9804 - val_loss: 0.0543 - val_accuracy: 0.9849
    Epoch 12/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0590 - accuracy: 0.9819 - val_loss: 0.0516 - val_accuracy: 0.9847
    Epoch 13/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0546 - accuracy: 0.9812 - val_loss: 0.0512 - val_accuracy: 0.9834
    Epoch 14/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0502 - accuracy: 0.9837 - val_loss: 0.0486 - val_accuracy: 0.9831
    Epoch 15/30
    180/180 [==============================] - 4s 24ms/step - loss: 0.0493 - accuracy: 0.9843 - val_loss: 0.0466 - val_accuracy: 0.9851
    Epoch 16/30
    180/180 [==============================] - 6s 30ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.0366 - val_accuracy: 0.9885
    Epoch 17/30
    180/180 [==============================] - 4s 19ms/step - loss: 0.0441 - accuracy: 0.9862 - val_loss: 0.0429 - val_accuracy: 0.9876
    Epoch 18/30
    180/180 [==============================] - 3s 19ms/step - loss: 0.0447 - accuracy: 0.9851 - val_loss: 0.0397 - val_accuracy: 0.9882
    Epoch 19/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0426 - accuracy: 0.9858 - val_loss: 0.0319 - val_accuracy: 0.9896
    Epoch 20/30
    180/180 [==============================] - 4s 19ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.0296 - val_accuracy: 0.9911
    Epoch 21/30
    180/180 [==============================] - 4s 21ms/step - loss: 0.0379 - accuracy: 0.9869 - val_loss: 0.0278 - val_accuracy: 0.9918
    Epoch 22/30
    180/180 [==============================] - 3s 19ms/step - loss: 0.0386 - accuracy: 0.9871 - val_loss: 0.0339 - val_accuracy: 0.9880
    Epoch 23/30
    180/180 [==============================] - 3s 19ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 0.0315 - val_accuracy: 0.9913
    Epoch 24/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.0390 - val_accuracy: 0.9858
    Epoch 25/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0349 - accuracy: 0.9895 - val_loss: 0.0264 - val_accuracy: 0.9911
    Epoch 26/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 0.0273 - val_accuracy: 0.9909
    Epoch 27/30
    180/180 [==============================] - 3s 19ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.0306 - val_accuracy: 0.9913
    Epoch 28/30
    180/180 [==============================] - 3s 19ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.0397 - val_accuracy: 0.9876
    Epoch 29/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0232 - val_accuracy: 0.9919
    Epoch 30/30
    180/180 [==============================] - 3s 18ms/step - loss: 0.0337 - accuracy: 0.9883 - val_loss: 0.0253 - val_accuracy: 0.9909
    


```python
plt.plot(history1.history["accuracy"], label = "training")
plt.plot(history1.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f39563fe6d0>




    
![output_21_1.png]({{ site.baseurl }}/images/output_21_1.png)
    


The plot above shows that model1 has a validation accuracy **around 99%**, which is much higher than the base rate. And there is no sign of overfitting.

## Model2: with text only:


```python
text_features = vectorize_layer(text_input)
text_features = shared_embedding(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.GlobalAveragePooling1D()(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.Dense(32, activation='relu')(text_features)

output2 = layers.Dense(2, name = "fake")(text_features)

# here's our model1:

model2 = keras.Model(
    inputs = text_input,
    outputs = output2
)

model2.summary()
```

    Model: "model_1"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     text (InputLayer)           [(None, 1)]               0         
                                                                     
     text_vectorization (TextVec  (None, 500)              0         
     torization)                                                     
                                                                     
     embedding (Embedding)       (None, 500, 10)           20000     
                                                                     
     dropout_2 (Dropout)         (None, 500, 10)           0         
                                                                     
     global_average_pooling1d_1   (None, 10)               0         
     (GlobalAveragePooling1D)                                        
                                                                     
     dropout_3 (Dropout)         (None, 10)                0         
                                                                     
     dense_1 (Dense)             (None, 32)                352       
                                                                     
     fake (Dense)                (None, 2)                 66        
                                                                     
    =================================================================
    Total params: 20,418
    Trainable params: 20,418
    Non-trainable params: 0
    _________________________________________________________________
    


```python
keras.utils.plot_model(model2)
```




    
![output_24_0.png]({{ site.baseurl }}/images/output_24_0.png)
    




```python
model2.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)

history2 = model2.fit(train, 
                    validation_data=val,
                    epochs = 30, 
                    verbose = True)
```

    Epoch 1/30
    

    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning:
    
    Input dict contained keys ['title'] which did not match any model input. They will be ignored by the model.
    
    

    180/180 [==============================] - 6s 27ms/step - loss: 0.5621 - accuracy: 0.7420 - val_loss: 0.3860 - val_accuracy: 0.8718
    Epoch 2/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.3045 - accuracy: 0.9003 - val_loss: 0.2461 - val_accuracy: 0.9324
    Epoch 3/30
    180/180 [==============================] - 5s 27ms/step - loss: 0.2264 - accuracy: 0.9251 - val_loss: 0.2025 - val_accuracy: 0.9378
    Epoch 4/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.1937 - accuracy: 0.9411 - val_loss: 0.1743 - val_accuracy: 0.9480
    Epoch 5/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.1732 - accuracy: 0.9472 - val_loss: 0.1560 - val_accuracy: 0.9571
    Epoch 6/30
    180/180 [==============================] - 5s 27ms/step - loss: 0.1565 - accuracy: 0.9547 - val_loss: 0.1515 - val_accuracy: 0.9573
    Epoch 7/30
    180/180 [==============================] - 5s 27ms/step - loss: 0.1475 - accuracy: 0.9591 - val_loss: 0.1362 - val_accuracy: 0.9616
    Epoch 8/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.1374 - accuracy: 0.9623 - val_loss: 0.1090 - val_accuracy: 0.9729
    Epoch 9/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.1276 - accuracy: 0.9646 - val_loss: 0.1245 - val_accuracy: 0.9644
    Epoch 10/30
    180/180 [==============================] - 5s 27ms/step - loss: 0.1220 - accuracy: 0.9665 - val_loss: 0.1195 - val_accuracy: 0.9698
    Epoch 11/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.1135 - accuracy: 0.9701 - val_loss: 0.1061 - val_accuracy: 0.9746
    Epoch 12/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.1123 - accuracy: 0.9697 - val_loss: 0.1042 - val_accuracy: 0.9722
    Epoch 13/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.1042 - accuracy: 0.9723 - val_loss: 0.0961 - val_accuracy: 0.9769
    Epoch 14/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.0966 - accuracy: 0.9734 - val_loss: 0.0914 - val_accuracy: 0.9764
    Epoch 15/30
    180/180 [==============================] - 5s 27ms/step - loss: 0.1009 - accuracy: 0.9723 - val_loss: 0.0900 - val_accuracy: 0.9756
    Epoch 16/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.0926 - accuracy: 0.9746 - val_loss: 0.0870 - val_accuracy: 0.9758
    Epoch 17/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.0896 - accuracy: 0.9756 - val_loss: 0.0812 - val_accuracy: 0.9789
    Epoch 18/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.0878 - accuracy: 0.9768 - val_loss: 0.0771 - val_accuracy: 0.9780
    Epoch 19/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.0834 - accuracy: 0.9773 - val_loss: 0.0846 - val_accuracy: 0.9773
    Epoch 20/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.0818 - accuracy: 0.9779 - val_loss: 0.0692 - val_accuracy: 0.9820
    Epoch 21/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.0765 - accuracy: 0.9780 - val_loss: 0.0670 - val_accuracy: 0.9842
    Epoch 22/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.0752 - accuracy: 0.9802 - val_loss: 0.0714 - val_accuracy: 0.9811
    Epoch 23/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.0720 - accuracy: 0.9793 - val_loss: 0.0728 - val_accuracy: 0.9789
    Epoch 24/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.0690 - accuracy: 0.9812 - val_loss: 0.0532 - val_accuracy: 0.9856
    Epoch 25/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.0687 - accuracy: 0.9804 - val_loss: 0.0665 - val_accuracy: 0.9822
    Epoch 26/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.0629 - accuracy: 0.9825 - val_loss: 0.0495 - val_accuracy: 0.9873
    Epoch 27/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.0622 - accuracy: 0.9824 - val_loss: 0.0570 - val_accuracy: 0.9862
    Epoch 28/30
    180/180 [==============================] - 5s 26ms/step - loss: 0.0601 - accuracy: 0.9832 - val_loss: 0.0570 - val_accuracy: 0.9838
    Epoch 29/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.0595 - accuracy: 0.9835 - val_loss: 0.0532 - val_accuracy: 0.9858
    Epoch 30/30
    180/180 [==============================] - 5s 25ms/step - loss: 0.0569 - accuracy: 0.9842 - val_loss: 0.0598 - val_accuracy: 0.9818
    


```python
plt.plot(history2.history["accuracy"], label = "training")
plt.plot(history2.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f39562599d0>




    
![output_26_1.png]({{ site.baseurl }}/images/output_26_1.png)
    


The plot above shows that model2 has a validation accuracy **around 98%**, which is much higher than the base rate. And there is no sign of overfitting.

## Model3: with both title and text


```python
# combine both features
main = layers.concatenate([title_features, text_features], axis = 1)

main = layers.Dense(32, activation='relu')(main)
output = layers.Dense(2, name = "fake")(main)

model3 = keras.Model(
    inputs = [title_input, text_input],
    outputs = output
)

model3.summary()
```

    Model: "model_2"
    __________________________________________________________________________________________________
     Layer (type)                   Output Shape         Param #     Connected to                     
    ==================================================================================================
     title (InputLayer)             [(None, 1)]          0           []                               
                                                                                                      
     text (InputLayer)              [(None, 1)]          0           []                               
                                                                                                      
     text_vectorization (TextVector  (None, 500)         0           ['title[0][0]',                  
     ization)                                                         'text[0][0]']                   
                                                                                                      
     embedding (Embedding)          (None, 500, 10)      20000       ['text_vectorization[0][0]',     
                                                                      'text_vectorization[1][0]']     
                                                                                                      
     dropout (Dropout)              (None, 500, 10)      0           ['embedding[0][0]']              
                                                                                                      
     dropout_2 (Dropout)            (None, 500, 10)      0           ['embedding[1][0]']              
                                                                                                      
     global_average_pooling1d (Glob  (None, 10)          0           ['dropout[0][0]']                
     alAveragePooling1D)                                                                              
                                                                                                      
     global_average_pooling1d_1 (Gl  (None, 10)          0           ['dropout_2[0][0]']              
     obalAveragePooling1D)                                                                            
                                                                                                      
     dropout_1 (Dropout)            (None, 10)           0           ['global_average_pooling1d[0][0]'
                                                                     ]                                
                                                                                                      
     dropout_3 (Dropout)            (None, 10)           0           ['global_average_pooling1d_1[0][0
                                                                     ]']                              
                                                                                                      
     dense (Dense)                  (None, 32)           352         ['dropout_1[0][0]']              
                                                                                                      
     dense_1 (Dense)                (None, 32)           352         ['dropout_3[0][0]']              
                                                                                                      
     concatenate (Concatenate)      (None, 64)           0           ['dense[0][0]',                  
                                                                      'dense_1[0][0]']                
                                                                                                      
     dense_2 (Dense)                (None, 32)           2080        ['concatenate[0][0]']            
                                                                                                      
     fake (Dense)                   (None, 2)            66          ['dense_2[0][0]']                
                                                                                                      
    ==================================================================================================
    Total params: 22,850
    Trainable params: 22,850
    Non-trainable params: 0
    __________________________________________________________________________________________________
    


```python
keras.utils.plot_model(model3)
```




    
![output_29_0.png]({{ site.baseurl }}/images/output_29_0.png)
    




```python
model3.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)

history3 = model3.fit(train, 
                    validation_data=val,
                    epochs = 30, 
                    verbose = True)
```

    Epoch 1/30
    180/180 [==============================] - 8s 39ms/step - loss: 0.1729 - accuracy: 0.9617 - val_loss: 0.0298 - val_accuracy: 0.9930
    Epoch 2/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0291 - accuracy: 0.9919 - val_loss: 0.0196 - val_accuracy: 0.9947
    Epoch 3/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0177 - val_accuracy: 0.9940
    Epoch 4/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.0172 - val_accuracy: 0.9938
    Epoch 5/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0119 - val_accuracy: 0.9962
    Epoch 6/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0122 - val_accuracy: 0.9942
    Epoch 7/30
    180/180 [==============================] - 7s 36ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 0.0101 - val_accuracy: 0.9969
    Epoch 8/30
    180/180 [==============================] - 7s 36ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0116 - val_accuracy: 0.9958
    Epoch 9/30
    180/180 [==============================] - 7s 36ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0083 - val_accuracy: 0.9973
    Epoch 10/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0106 - val_accuracy: 0.9969
    Epoch 11/30
    180/180 [==============================] - 7s 36ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0083 - val_accuracy: 0.9971
    Epoch 12/30
    180/180 [==============================] - 7s 36ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0107 - val_accuracy: 0.9964
    Epoch 13/30
    180/180 [==============================] - 7s 38ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0092 - val_accuracy: 0.9971
    Epoch 14/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0070 - val_accuracy: 0.9978
    Epoch 15/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0104 - val_accuracy: 0.9967
    Epoch 16/30
    180/180 [==============================] - 7s 38ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.0055 - val_accuracy: 0.9989
    Epoch 17/30
    180/180 [==============================] - 7s 38ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0077 - val_accuracy: 0.9987
    Epoch 18/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0081 - val_accuracy: 0.9976
    Epoch 19/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0209 - val_accuracy: 0.9924
    Epoch 20/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0032 - val_accuracy: 0.9996
    Epoch 21/30
    180/180 [==============================] - 7s 36ms/step - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.0057 - val_accuracy: 0.9987
    Epoch 22/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0043 - val_accuracy: 0.9989
    Epoch 23/30
    180/180 [==============================] - 7s 38ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.0022 - val_accuracy: 0.9998
    Epoch 24/30
    180/180 [==============================] - 7s 38ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0032 - val_accuracy: 0.9991
    Epoch 25/30
    180/180 [==============================] - 7s 40ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0032 - val_accuracy: 0.9996
    Epoch 26/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0040 - val_accuracy: 0.9993
    Epoch 27/30
    180/180 [==============================] - 7s 39ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9987
    Epoch 28/30
    180/180 [==============================] - 7s 38ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9996
    Epoch 29/30
    180/180 [==============================] - 7s 36ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9984
    Epoch 30/30
    180/180 [==============================] - 7s 37ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0027 - val_accuracy: 0.9996
    


```python
plt.plot(history3.history["accuracy"], label = "training")
plt.plot(history3.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f394fa7afd0>




    
![output_31_2.png]({{ site.baseurl }}/images/output_31_2.png)
    


The plot above shows that model3 has a validation accuracy **above 99% and very close to 100%**, which is incredible. The result does match what I expected. And there is no sign of overfitting.

# §4. Model Evaluation

Our best model is: `model3`. Let's test this model on unseen test data and see its model performance:


```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
test_df = pd.read_csv(test_url)

# convert this data using the make_dataset() function
test = make_dataset(test_df)

# evaluate the model3 performance
model3.evaluate(test)
```

    225/225 [==============================] - 3s 15ms/step - loss: 0.0350 - accuracy: 0.9914
    




    [0.03500250726938248, 0.9914027452468872]



Great! the testing accuracy of model3 is 99%! I am very satisfied with this result. And it leads me to a conclusion that when seeking to detect fake news, it would better for algorithms to use both the title and the text for a higher accuracy score.

# §5. Embedding Visualization

Finally, we can visualize on the embedding that the model3 contains. Maybe there was some patterns or associations in the words that the model found useful when distinguishing real news from fake news? This procedure was demonstrated in [here](https://nbviewer.org/github/PhilChodrow/PIC16B/blob/master/lectures/tf/tf-3.ipynb).


```python
weights = model3.get_layer('embedding').get_weights()[0] # get the weights from the embedding layer
vocab = vectorize_layer.get_vocabulary()                # get the vocabulary from our data prep for later

pca = PCA(n_components=2)
weights = pca.fit_transform(weights)

embedding_df = pd.DataFrame({
    'word' : vocab, 
    'x0'   : weights[:,0],
    'x1'   : weights[:,1]
})
```



```python
fig = px.scatter(embedding_df, 
                 x = "x0", 
                 y = "x1", 
                 size = list(np.ones(len(embedding_df))*2),
                 size_max = 4,
                 hover_name = "word")
fig.show()
```


{% include embedding2.html %}


From above, it's interesting to see that there is some associations in words like `trumps`, `myanmar`, `obamas`, `russias`, `rohingya` and `chinas`. These words occur very frequently when discussing international policies or conflicts.
