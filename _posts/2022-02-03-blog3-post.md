---
layout: post
title: My Blog Post 3
---

In this Blog Post, I’ll use webscraping to answer this question: `What movie or TV shows share actors with your favorite movie or show?`

The idea of the question above is that, if TV show Y has many of the same actors as TV show X, and I like X, I might also enjoy Y.

This post has two parts. In the first, larger part, I’ll write a webscraper for finding shared actors on IMDB. In the second, smaller part, I’ll use the results from your scraper to make recommendations.


```python
# The followings are the Packages/Modules required in this post.
import scrapy
import pandas as pd
from plotly import express as px
```

# §1. Setup

## §1.1. Locate the Starting IMDB Page

First, let's pick one favorite movies or TV shows, and locate its IMDB page. For example, my favorite movie is ***Spider-Man: No Way Home***. Its IMDB page is at:


```python
URL = "https://www.imdb.com/title/tt10872600/"
```

## §1.2. Dry-Run Navigation
Now, we’re just going to practice clicking through the navigation steps that our scraper will take.

First, click on the Cast & Crew link. This will take you to a page with URL of the form

```
<original_url>fullcredits/
```

Next, scroll until you see the Series Cast section. Click on the portrait of one of the actors. This will take you to a page with a different-looking URL. For example, the URL for **Tom Holland**, *Peter Parker / Spider-Man*, is

```
https://www.imdb.com/name/nm4043618/
```

Finally, scroll down until you see the actor’s Filmography section. Note the titles of a few movies and TV shows in this section.

Now, everything below is just replicating this process using **scrapy**.

## §1.3 Initialize Project

1. I first create a new GitHub repository, and sync it with GitHub Desktop. This repository will house my scraper so that I can commit and push each time I made changes.
2. Open a terminal in the location of my repository on my laptop, and type:

```
conda activate PIC16B
scrapy startproject IMDB_scraper
cd IMDB_scraper
```

## §1.4 Tweak Settings

For now, add the following line to the file `settings.py`:

```python
CLOSESPIDER_PAGECOUNT = 20
```

This line just prevents my scraper from downloading too much data while you’re still testing things out. I’ll remove this line later.

# §2. Write Scraper

Create a file inside the `spiders` directory called `imdb_spider.py`. Add the following lines to the file:

```python
class ImdbSpider(scrapy.Spider):
    name = 'imdb_spider'
    
    start_urls = ['https://www.imdb.com/title/tt10872600/']
```

If you want to use your favorite movie or TV show, just replace the entry of `start_urls` with the URL.

Now, implement three parsing methods for the `ImdbSpider` class.

- To begin with a movie page and do the navigation, we can define a method of **`parse(self, response)`**:

This method assumes that we start on a movie page, and then navigate to the Cast & Crew page by merging `fullcredits` to the end of current page link. Once there, call `parse_full_credits(self,response)` by using the `callback` argument to a yielded `scrapy.Request`.

In code:

```python
def parse(self, response):
    """
    assumption: start on a movie page
    
    effect: navigate to the Cast & Crew page by merging `fullcredits` to the end of current page link while
    calling `parse_full_credits(self,response)` using the `callback` argument to a yielded `scrapy.Request`
    
    output: does not return any data
    """
    
    # navigate to the Cast & Crew page
    url = response.urljoin("fullcredits")
    # call parse_full_credits method
    yield scrapy.Request(url, callback = self.parse_full_credits)
```


- To make the above method work, we need **`parse_full_credits(self, response)`**:

This method assumes that we start on the Cast & Crew page, and then navigate to a list of of relative paths, one for each actor. Once there, call `parse_actor_page(self, response)` by using the `callback` argument to a yielded `scrapy.Request`.


In code:

```python
def parse_full_credits(self, response):
    """
    assumption: start on the Cast & Crew page
    
    effect: navigate to each relative path for the corresponding actor while calling
    `parse_actor_page(self, response)` using the `callback` argument to a yielded `scrapy.Request`
    
    output: does not return any data
    """
    # navigate to each relative path for the corresponding actor
    for actor_link in [a.attrib["href"] for a in response.css("td.primary_photo a")]:
        # call parse_actor_page method
        yield scrapy.Request(response.urljoin(actor_link), callback = self.parse_actor_page)
```


- To make the above method work, we still need **`parse_actor_page(self, response)`**:

This method assumes that we start on the page of an actor, and then for each of the movies or TV shows on which that actor has worked, it yields a dictionary with two key-value pairs, of the form `{"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}`.

Note: determine both the name of the actor and the name of each movie or TV show, we can use the following selectors:

`"span.itemprop ::text"` --- get the actor's name in the actor page


`'div.filmo-row[id^=actor] a ::text'` --- get the title of movie/TV show inside a filmo section named actor under Filmography

In code:

```python
def parse_actor_page(self, response):
    """
    assumption: start on the page of an actor
    
    effect: for each of the movies or TV shows on which that actor has worked, it yields
    a dictionary with two key-value pairs.
    
    output: return data as a dictionary with two key-value pairs
    """
    # get the name of the actor
    actor_name = response.css("span.itemprop ::text").get()
    # get all the titles of movies and TV shows with id that starts with "actor" only.
    titles_actor_only = response.css('div.filmo-row[id^=actor] a ::text').getall()
    # prepare to store as a column for actors name and a column for movies or TV shows titles
    for title in titles_actor_only:
        yield {
            "actor" : actor_name,
            "movie_or_TV_name" : title
        }
```

Once these methods above are correctly implemented, Let's run the follwing command while deleting
`CLOSESPIDER_PAGECOUNT = 20` in the `settings.py`.

```
scrapy crawl imdb_spider -o movies.csv
```

It'll create a .csv file with a column for actors and a column for movies or TV shows.

# §3. Make Recommendations

Yessss~ We're almost here! To help display of the results, we compute a sorted list with the top movies and TV shows that share actors with my favorite movie or TV show. For example, here’s the list I obtained for ***Spider-Man: No Way Home***. Of course, most shows will “share” the most actors with themselves.

Here's how I make a table of movies with (10) most number of shared actors using pandas:


```python
movies = pd.read_csv("movies.csv")
```


```python
# get the top 10 shared actors movies/TV shows
top10 = movies["movie_or_TV_name"].value_counts().head(10)
# convert to dataframe
top10 = top10.to_frame().reset_index()
# update index for displaying
top10.columns = ['movie', 'number of shared actors']
top10
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movie</th>
      <th>number of shared actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Spider-Man: No Way Home</td>
      <td>63</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Spider-Man: Homecoming</td>
      <td>8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Spider-Man: Far from Home</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Spider-Man 3</td>
      <td>7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Richard Jewell</td>
      <td>6</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Spider-Man 2</td>
      <td>6</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Avengers: Endgame</td>
      <td>6</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Doom Patrol</td>
      <td>6</td>
    </tr>
    <tr>
      <th>8</th>
      <td>The Daily Bugle</td>
      <td>5</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Robot Chicken</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>



Or we can do a interactive data graphics with Plotly:


```python
fig = px.bar(top10, x = "movie", y = "number of shared actors",
            color = "number of shared actors",
            title = "Distribution of Movies with Most Shared Actors")
fig.show()
```

{% include movies_distribution.html %}

At the end, here's a [link](https://github.com/leozhang233/Scrapy/tree/main/IMDB_scraper) to the GitHub repository for my scraper project.
