---
layout: post
title: My Blog Post 5
---

In this blog post, I’ll write a tutorial on image classification in `Tensorflow` with details of several new skills and concepts.

So what is `Tensorflow`? As been mentioned by Professor Chodrow, Tensorflow is a very powerful source platform for machine learning, which was developed by Google researchers. It is mainly used for classification, perception, large numerical computations, and so forth.

Notice: the following code is written in `Google Colab`. One benefit of using this rather than Jupyter Notebook is that `Google Colab` allows us to enable GPU for a much faster training speed it involves graphical models. To do that, we can click *Change Runtime Type* under the *Runtime* menu, and then select *GPU*.

The main idea about this post is that given a large dataset with many images of either dogs and cats, I are going to use `Tensorflow` to help us distinguish them. You may find this [Transfer Learning Tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning) very useful.

# §1. Load Packages and Obtain Data


```python
# The followings are the Packages/Modules required in this post.
import os
import tensorflow as tf
from tensorflow.keras import utils, layers, models
import matplotlib.pyplot as plt
import numpy as np
```

To start, let's obtain the data provided by the TensorFlow team that contains labeled images of cats and dogs. Then I run the following code:


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.
    

You don't need to fully understand the code above. Basically, what it does is that I created TensorFlow `Datasets` for training, validation, and testing. While `utils.image_dataset_from_directory` allows us to generates a Dataset from image files in a directory, its argument `shuffle` is asking whether to shuffle the data. `batch_size` and `image_size` are just the size of the batches of data and the size to resize images to after they are read from disk, respectively.

## Working with Datasets

Next, I will demonstrate three random cats and three random dogs using the function `TwoRow_Visualization` created below just for visualizatation where the top row will be cats and the bottom row will be dogs. Note: the command `dataset.take(1)` can help retrieve one batch (32 images with labels) from the the dataset that we used.


```python
def TwoRow_Visualization(data):
    class_names = data.class_names
    plt.figure(figsize=(10, 8))
    for images, labels in data.take(1):
        # get the index of the three random cats
        cat_index = np.where(labels == 0)[0][:3]
        # get the index of the three random dogs
        dog_index = np.where(labels == 1)[0][:3]
        # add the two index together
        index = np.append(cat_index, dog_index)
        for i in range(6):
            ax = plt.subplot(2, 3, i + 1)
            plt.imshow(images[index[i]].numpy().astype("uint8"))
            plt.title(class_names[labels[index[i]]])
            plt.axis("off")
```


```python
# demonstration with the training dataset:
TwoRow_Visualization(train_dataset)
```


![output_9_0.png]({{ site.baseurl }}/images/output_9_0.png)
    


## Check Label Frequencies

In addition, in order to see how many images of cats and dogs are in the training dataset, I used `train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()`, which will give me an iterator that help iterate all the labels from the training dataset. Note: the label, `0`, represents `cat`, and the label, `1`, represents `dog`.


```python
freq = {"cat":0 , "dog": 0}
labels_iterator = train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
for labels in labels_iterator:
    if labels == 0:
        freq["cat"] += 1
    else:
        freq["dog"] += 1
freq
```




    {'cat': 1000, 'dog': 1000}



Great! there are 1000 cats and 1000 dogs in the training dataset.

Before creating models, we can paste the following code and run it. This is technical code related to rapidly reading data. More information can be found [here](https://www.tensorflow.org/guide/data_performance).


```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

# §2. First Model

To build our first model, I used a `tf.keras.Sequential` to help build a model. After several trials of fitting, I find that using at least two `Conv2D` layers, at least two `MaxPooling2D` layers, at least one `Flatten` layer, at least one `Dense` layer, and at least one `Dropout` layer maybe useful in improve model performance. With the training model, I can use it to plot the history of the accuracy on both the training and validation sets.

This is my first model, `model1`:


```python
model1 = models.Sequential([
    layers.Conv2D(160, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(80, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(80, activation='relu'),
    layers.Dropout(0.1),
    layers.Dense(2)
])
```


```python
model1.summary()
```

    Model: "sequential_8"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     conv2d_24 (Conv2D)          (None, 158, 158, 160)     4480      
                                                                     
     max_pooling2d_16 (MaxPoolin  (None, 79, 79, 160)      0         
     g2D)                                                            
                                                                     
     conv2d_25 (Conv2D)          (None, 77, 77, 80)        115280    
                                                                     
     max_pooling2d_17 (MaxPoolin  (None, 38, 38, 80)       0         
     g2D)                                                            
                                                                     
     flatten_12 (Flatten)        (None, 115520)            0         
                                                                     
     dense_17 (Dense)            (None, 80)                9241680   
                                                                     
     dropout_8 (Dropout)         (None, 80)                0         
                                                                     
     dense_18 (Dense)            (None, 2)                 162       
                                                                     
    =================================================================
    Total params: 9,361,602
    Trainable params: 9,361,602
    Non-trainable params: 0
    _________________________________________________________________
    

The syntax of training a model on a Dataset is very simple. Just like this:
```
history = model.fit(train_dataset, 
                    epochs=20, 
                    validation_data=validation)
```

Note: For this post, training for 20 epochs with the Dataset settings described above should be sufficient to see our model performance.


```python
model1.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history1 = model1.fit(train_dataset,
                    epochs=20, validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 8s 106ms/step - loss: 33.4726 - accuracy: 0.4965 - val_loss: 0.6933 - val_accuracy: 0.4950
    Epoch 2/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.6855 - accuracy: 0.5435 - val_loss: 0.6938 - val_accuracy: 0.4975
    Epoch 3/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.6768 - accuracy: 0.5335 - val_loss: 0.7057 - val_accuracy: 0.5161
    Epoch 4/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.6272 - accuracy: 0.5910 - val_loss: 0.8169 - val_accuracy: 0.5000
    Epoch 5/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.5565 - accuracy: 0.6510 - val_loss: 1.0314 - val_accuracy: 0.5111
    Epoch 6/20
    63/63 [==============================] - 6s 95ms/step - loss: 0.5123 - accuracy: 0.6965 - val_loss: 1.5540 - val_accuracy: 0.5347
    Epoch 7/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.4592 - accuracy: 0.7380 - val_loss: 1.4557 - val_accuracy: 0.5396
    Epoch 8/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.4019 - accuracy: 0.7685 - val_loss: 1.7883 - val_accuracy: 0.5433
    Epoch 9/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.4181 - accuracy: 0.7720 - val_loss: 1.7042 - val_accuracy: 0.5371
    Epoch 10/20
    63/63 [==============================] - 6s 95ms/step - loss: 0.3484 - accuracy: 0.8015 - val_loss: 2.5158 - val_accuracy: 0.5408
    Epoch 11/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.3083 - accuracy: 0.8185 - val_loss: 3.7783 - val_accuracy: 0.5606
    Epoch 12/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.3737 - accuracy: 0.7925 - val_loss: 2.6967 - val_accuracy: 0.5384
    Epoch 13/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.3044 - accuracy: 0.8295 - val_loss: 2.8052 - val_accuracy: 0.5520
    Epoch 14/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.2873 - accuracy: 0.8465 - val_loss: 2.9877 - val_accuracy: 0.5458
    Epoch 15/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.2512 - accuracy: 0.8545 - val_loss: 4.2677 - val_accuracy: 0.5408
    Epoch 16/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.2214 - accuracy: 0.8805 - val_loss: 4.2641 - val_accuracy: 0.5396
    Epoch 17/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.2164 - accuracy: 0.8895 - val_loss: 4.6724 - val_accuracy: 0.5359
    Epoch 18/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.1986 - accuracy: 0.8970 - val_loss: 4.9753 - val_accuracy: 0.5371
    Epoch 19/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.1753 - accuracy: 0.9085 - val_loss: 4.0889 - val_accuracy: 0.5606
    Epoch 20/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.2704 - accuracy: 0.8810 - val_loss: 4.1305 - val_accuracy: 0.5545
    


```python
plt.plot(history1.history["accuracy"], label = "training")
plt.plot(history1.history["val_accuracy"], label = "validation")
plt.axhline(y=0.52, color='r', linestyle='dashed', label = "expectation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fc1b23827d0>




    
![output_19_1.png]({{ site.baseurl }}/images/output_19_1.png)
    


As can be seen, the accuracy of my `model1` stabilized between **50%** and **56%** during training. But overall, the accuracy is higher than the baseline, **52%**. Also, the training accuracy is much higher than the validation accuracy, which indicates that there is an **overfitting** in `model1`.

# §3. Model with Data Augmentation

For my `model2`, I will add some `data augmentation` layers. `Data augmentation` can be considered as one of the ways that improve model performance by forming new and different dataset. In our example, a picture of a dog is still a picture of a dog no matter how much we flip or rotate it.

The following are the two layers that help us flip and rotate the image, and I will display a plot of the original image and a few copies just for visualizing.

- `tf.keras.layers.RandomFlip()` is a layer which randomly flips images during training.


```python
data_augmentation = tf.keras.Sequential([
  layers.RandomFlip("horizontal_and_vertical"),
])
```


```python
for image, _ in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    first_image = image[0]
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
        plt.imshow(augmented_image[0] / 255)
        plt.axis('off')
```


    
![output_23_0.png]({{ site.baseurl }}/images/output_23_0.png)
    


- `tf.keras.layers.RandomRotation()` is a layer which randomly rotates images during training.


```python
data_augmentation2 = tf.keras.Sequential([
  layers.RandomRotation(0.2),
])
```


```python
for image, _ in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    first_image = image[0]
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        augmented_image = data_augmentation2(tf.expand_dims(first_image, 0))
        plt.imshow(augmented_image[0] / 255)
        plt.axis('off')
```


    
![output_26_0.png]({{ site.baseurl }}/images/output_26_0.png)
    


Here's my `model2`, which is very similar to my `model1` but have the two augmentation layers at the beginning.


```python
model2 = tf.keras.Sequential([
    layers.RandomFlip('horizontal_and_vertical'),
    layers.RandomRotation(0.2),
    layers.Conv2D(160, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(80, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(80, activation='relu'),
    layers.Dropout(0.1),
    layers.Dense(2)
])
```


```python
model2.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])

history2 = model2.fit(train_dataset,
                      epochs=20, validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 7s 99ms/step - loss: 41.7817 - accuracy: 0.5220 - val_loss: 0.6927 - val_accuracy: 0.5173
    Epoch 2/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.6926 - accuracy: 0.5255 - val_loss: 0.6931 - val_accuracy: 0.5136
    Epoch 3/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.6914 - accuracy: 0.5260 - val_loss: 0.6936 - val_accuracy: 0.5347
    Epoch 4/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6900 - accuracy: 0.5360 - val_loss: 0.6977 - val_accuracy: 0.5248
    Epoch 5/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.6872 - accuracy: 0.5305 - val_loss: 0.7048 - val_accuracy: 0.5198
    Epoch 6/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.6913 - accuracy: 0.5315 - val_loss: 0.6901 - val_accuracy: 0.5359
    Epoch 7/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6932 - accuracy: 0.5460 - val_loss: 0.6985 - val_accuracy: 0.5297
    Epoch 8/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6883 - accuracy: 0.5765 - val_loss: 0.6931 - val_accuracy: 0.5606
    Epoch 9/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.6806 - accuracy: 0.5680 - val_loss: 0.6995 - val_accuracy: 0.5012
    Epoch 10/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.6915 - accuracy: 0.5130 - val_loss: 0.6993 - val_accuracy: 0.5050
    Epoch 11/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.6852 - accuracy: 0.5305 - val_loss: 0.6913 - val_accuracy: 0.5557
    Epoch 12/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6853 - accuracy: 0.5565 - val_loss: 0.6871 - val_accuracy: 0.5644
    Epoch 13/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6762 - accuracy: 0.6020 - val_loss: 0.7089 - val_accuracy: 0.5668
    Epoch 14/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6721 - accuracy: 0.5935 - val_loss: 0.7137 - val_accuracy: 0.5594
    Epoch 15/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6736 - accuracy: 0.6030 - val_loss: 0.7062 - val_accuracy: 0.5953
    Epoch 16/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.6677 - accuracy: 0.6100 - val_loss: 0.7109 - val_accuracy: 0.6040
    Epoch 17/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.6706 - accuracy: 0.6080 - val_loss: 0.6950 - val_accuracy: 0.6176
    Epoch 18/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6670 - accuracy: 0.5955 - val_loss: 0.6908 - val_accuracy: 0.5891
    Epoch 19/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6610 - accuracy: 0.6200 - val_loss: 0.7101 - val_accuracy: 0.5668
    Epoch 20/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6634 - accuracy: 0.6090 - val_loss: 0.6978 - val_accuracy: 0.6040
    


```python
plt.plot(history2.history["accuracy"], label = "training")
plt.plot(history2.history["val_accuracy"], label = "validation")
plt.axhline(y=0.55, color='r', linestyle='dashed', label = "expectation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fc19d5d04d0>




    
![output_30_1.png]({{ site.baseurl }}/images/output_30_1.png)
    


As can be seen, the accuracy of my `model2` stabilized between **50%** and **62%** during training. But overall, the accuracy is higher than the baseline, **55%**. In comparison to the accuracy obtained with model1, the accuracy of my `model2` is fluctuating and unstable. Although the validation accuracy after epoch 10 is higher than the baseline, I don't think this model did a very good job in fitting than model1. In addition, the training accuracy is not higher than the validation accuracy, which indicates that there is no sign of the **overfitting** in `model2`.

# §4. Data Preprocessing

Data transformation can be sometimes very useful for modeling fitting, such as scaling the weights. Scaling before the training can help our model focus on the actual signal in the data. For my next model, I will create a `preprocessing` layer named preprocessor which can be seen in the following lines of code:


```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```

Here's my `model3`, which is a bit similar to my `model2` but have the preprocessing layers at the beginning and different values modified for the other layers.


```python
model3 = tf.keras.Sequential([
    preprocessor,                      
    layers.RandomFlip('horizontal_and_vertical'),
    layers.RandomRotation(0.2),
    layers.Conv2D(160, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(80, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dense(40, activation='relu'),
    layers.Flatten(),
    layers.Dropout(0.15),
    layers.Dense(2)
])
```


```python
model3.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])

history3 = model3.fit(train_dataset,
                      epochs=20, validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 8s 103ms/step - loss: 0.7117 - accuracy: 0.5560 - val_loss: 0.6597 - val_accuracy: 0.6238
    Epoch 2/20
    63/63 [==============================] - 7s 100ms/step - loss: 0.6666 - accuracy: 0.5855 - val_loss: 0.6590 - val_accuracy: 0.6151
    Epoch 3/20
    63/63 [==============================] - 7s 101ms/step - loss: 0.6506 - accuracy: 0.6255 - val_loss: 0.6406 - val_accuracy: 0.6324
    Epoch 4/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.6411 - accuracy: 0.6185 - val_loss: 0.6368 - val_accuracy: 0.6312
    Epoch 5/20
    63/63 [==============================] - 7s 99ms/step - loss: 0.6193 - accuracy: 0.6485 - val_loss: 0.6200 - val_accuracy: 0.6522
    Epoch 6/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.6258 - accuracy: 0.6365 - val_loss: 0.6369 - val_accuracy: 0.6473
    Epoch 7/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.6025 - accuracy: 0.6765 - val_loss: 0.5953 - val_accuracy: 0.6696
    Epoch 8/20
    63/63 [==============================] - 7s 100ms/step - loss: 0.5753 - accuracy: 0.7010 - val_loss: 0.6251 - val_accuracy: 0.6609
    Epoch 9/20
    63/63 [==============================] - 7s 100ms/step - loss: 0.6057 - accuracy: 0.6865 - val_loss: 0.5822 - val_accuracy: 0.7166
    Epoch 10/20
    63/63 [==============================] - 7s 100ms/step - loss: 0.5746 - accuracy: 0.7055 - val_loss: 0.6032 - val_accuracy: 0.6498
    Epoch 11/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.5788 - accuracy: 0.6970 - val_loss: 0.5804 - val_accuracy: 0.6968
    Epoch 12/20
    63/63 [==============================] - 7s 100ms/step - loss: 0.5615 - accuracy: 0.7065 - val_loss: 0.5711 - val_accuracy: 0.7005
    Epoch 13/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.5629 - accuracy: 0.7065 - val_loss: 0.5619 - val_accuracy: 0.7042
    Epoch 14/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.5487 - accuracy: 0.7205 - val_loss: 0.5361 - val_accuracy: 0.7302
    Epoch 15/20
    63/63 [==============================] - 7s 100ms/step - loss: 0.5623 - accuracy: 0.7140 - val_loss: 0.6039 - val_accuracy: 0.6918
    Epoch 16/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.5504 - accuracy: 0.7085 - val_loss: 0.5484 - val_accuracy: 0.7079
    Epoch 17/20
    63/63 [==============================] - 7s 100ms/step - loss: 0.5300 - accuracy: 0.7305 - val_loss: 0.5537 - val_accuracy: 0.7252
    Epoch 18/20
    63/63 [==============================] - 7s 99ms/step - loss: 0.5303 - accuracy: 0.7320 - val_loss: 0.5280 - val_accuracy: 0.7389
    Epoch 19/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.5351 - accuracy: 0.7290 - val_loss: 0.5339 - val_accuracy: 0.7191
    Epoch 20/20
    63/63 [==============================] - 7s 99ms/step - loss: 0.5392 - accuracy: 0.7315 - val_loss: 0.5492 - val_accuracy: 0.7302
    


```python
plt.plot(history3.history["accuracy"], label = "training")
plt.plot(history3.history["val_accuracy"], label = "validation")
plt.axhline(y=0.70, color='r', linestyle='dashed', label = "expectation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fc1b2957690>




    
![output_36_1.png]({{ site.baseurl }}/images/output_36_1.png)
    


As can be seen, the accuracy of my `model3` stabilized between **62%** and **74%** during training. Although at the begining, the accuracy is not very high, after epoch 8, the accuracy is going up and larger than the baseline, **70%**. In comparison to the accuracy obtained with model1, the accuracy of my `model3` does achieve a high accuracy than the model1. In addition, the training accuracy is not higher than the validation accuracy, which indicates that there is no sign of the **overfitting** in `model3`.

# §5. Transfer Learning

The idea of transfer learning is that we can apply a pre-existing model for our task in distinguishing between cats and dogs. To do that, all we need to do is to first access a pre-existing “base model”, incorporate it into a full model that we want to train. From the following lines of code, you can see that I downloaded `MobileNetV2` and configured it as a layer named `base_model_layer`.


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

Here's my `model4`:


```python
model4 = tf.keras.Sequential([
  preprocessor,                      
  layers.RandomFlip('horizontal_and_vertical'),
  layers.RandomRotation(0.2),
  base_model_layer,
  layers.GlobalMaxPooling2D(),
  layers.Dropout(0.15),
  layers.Dense(2)
])
```


```python
model4.summary()
```

    Model: "sequential_38"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model_3 (Functional)        (None, 160, 160, 3)       0         
                                                                     
     random_flip_28 (RandomFlip)  (None, 160, 160, 3)      0         
                                                                     
     random_rotation_28 (RandomR  (None, 160, 160, 3)      0         
     otation)                                                        
                                                                     
     model_4 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                     
     global_max_pooling2d_1 (Glo  (None, 1280)             0         
     balMaxPooling2D)                                                
                                                                     
     dropout_35 (Dropout)        (None, 1280)              0         
                                                                     
     dense_70 (Dense)            (None, 2)                 2562      
                                                                     
    =================================================================
    Total params: 2,260,546
    Trainable params: 2,562
    Non-trainable params: 2,257,984
    _________________________________________________________________
    

From the summary above, we can see that there are a total of 2,260,546 parameters, including 2,257,984 non-trainable parameters in our model!


```python
model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history4 = model4.fit(train_dataset,
                    epochs=20, validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 8s 77ms/step - loss: 0.9671 - accuracy: 0.7640 - val_loss: 0.1702 - val_accuracy: 0.9480
    Epoch 2/20
    63/63 [==============================] - 4s 59ms/step - loss: 0.5773 - accuracy: 0.8450 - val_loss: 0.1395 - val_accuracy: 0.9579
    Epoch 3/20
    63/63 [==============================] - 4s 59ms/step - loss: 0.5295 - accuracy: 0.8625 - val_loss: 0.1173 - val_accuracy: 0.9691
    Epoch 4/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.4247 - accuracy: 0.8840 - val_loss: 0.1016 - val_accuracy: 0.9666
    Epoch 5/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.4523 - accuracy: 0.8825 - val_loss: 0.1061 - val_accuracy: 0.9678
    Epoch 6/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.3371 - accuracy: 0.9005 - val_loss: 0.0987 - val_accuracy: 0.9691
    Epoch 7/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.3609 - accuracy: 0.8975 - val_loss: 0.0926 - val_accuracy: 0.9715
    Epoch 8/20
    63/63 [==============================] - 5s 66ms/step - loss: 0.3282 - accuracy: 0.9075 - val_loss: 0.0907 - val_accuracy: 0.9666
    Epoch 9/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.3022 - accuracy: 0.9000 - val_loss: 0.1021 - val_accuracy: 0.9691
    Epoch 10/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.3787 - accuracy: 0.8905 - val_loss: 0.0854 - val_accuracy: 0.9653
    Epoch 11/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.2775 - accuracy: 0.9195 - val_loss: 0.0783 - val_accuracy: 0.9740
    Epoch 12/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.2794 - accuracy: 0.9160 - val_loss: 0.1859 - val_accuracy: 0.9530
    Epoch 13/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.3475 - accuracy: 0.9080 - val_loss: 0.0941 - val_accuracy: 0.9678
    Epoch 14/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.2405 - accuracy: 0.9240 - val_loss: 0.0885 - val_accuracy: 0.9678
    Epoch 15/20
    63/63 [==============================] - 4s 59ms/step - loss: 0.2695 - accuracy: 0.9195 - val_loss: 0.0849 - val_accuracy: 0.9691
    Epoch 16/20
    63/63 [==============================] - 4s 59ms/step - loss: 0.3115 - accuracy: 0.9045 - val_loss: 0.1589 - val_accuracy: 0.9579
    Epoch 17/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.3146 - accuracy: 0.9105 - val_loss: 0.1017 - val_accuracy: 0.9604
    Epoch 18/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.2563 - accuracy: 0.9260 - val_loss: 0.0856 - val_accuracy: 0.9691
    Epoch 19/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.2514 - accuracy: 0.9190 - val_loss: 0.0750 - val_accuracy: 0.9728
    Epoch 20/20
    63/63 [==============================] - 4s 58ms/step - loss: 0.2489 - accuracy: 0.9190 - val_loss: 0.0856 - val_accuracy: 0.9691
    


```python
plt.plot(history4.history["accuracy"], label = "training")
plt.plot(history4.history["val_accuracy"], label = "validation")
plt.axhline(y=0.95, color='r', linestyle='dashed', label = "expectation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fc081012710>




    
![output_44_1.png]({{ site.baseurl }}/images/output_44_1.png)
    


As can be seen, the accuracy of my `model4` stabilized between **95%** and **97%** during training. But overall, the accuracy is constantly higher than the baseline, **95%**. In comparison to the accuracy obtained with my other models, the accuracy of my `model4` is really high, stable, and reliable. In addition, the training accuracy is not higher than the validation accuracy, which indicates that there is no sign of the **overfitting** in `model4`.

# §6. Score on Test Data

Finally, let's use our most performant model, `model4` to test its score on the test dataset.


```python
model4.evaluate(test_dataset, verbose = 2)
```

    6/6 - 1s - loss: 0.0660 - accuracy: 0.9688 - 503ms/epoch - 84ms/step
    




    [0.06601107865571976, 0.96875]



As can be seen, we got about 97% accuracy on the test dataset, which is incredible!
